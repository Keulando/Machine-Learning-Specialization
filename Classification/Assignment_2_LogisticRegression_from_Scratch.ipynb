{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:53:20.702325Z",
     "start_time": "2018-03-06T14:53:20.697324Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:50:15.715100Z",
     "start_time": "2018-03-06T14:50:15.240540Z"
    }
   },
   "outputs": [],
   "source": [
    "products=pd.read_csv(\"amazon_baby_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:50:53.935534Z",
     "start_time": "2018-03-06T14:50:53.923031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:51:51.397811Z",
     "start_time": "2018-03-06T14:51:51.389787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    26579\n",
       "-1    26493\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:56:17.470538Z",
     "start_time": "2018-03-06T14:56:17.466039Z"
    }
   },
   "outputs": [],
   "source": [
    "imp_words=json.load(open(\"important_words.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:12:44.635854Z",
     "start_time": "2018-03-06T15:12:44.629859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imp_words[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:57:52.675591Z",
     "start_time": "2018-03-06T14:57:52.662568Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "products=products.fillna({\"review\":\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:05:53.529536Z",
     "start_time": "2018-03-06T15:05:53.520036Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    import re\n",
    "    \n",
    "    punctuation=string.punctuation #list of puncts\n",
    "    clean=re.sub(r\"[{}]\".format(punctuation),\"\",text)\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:05:54.602276Z",
     "start_time": "2018-03-06T15:05:53.966183Z"
    }
   },
   "outputs": [],
   "source": [
    "products[\"clean_review\"]=products[\"review\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:10:55.093597Z",
     "start_time": "2018-03-06T15:09:20.892066Z"
    }
   },
   "outputs": [],
   "source": [
    "# count the words of imp_words that occur in clear_review\n",
    "for word in imp_words:\n",
    "    products[word] = products['clean_review'].apply(lambda s : s.split().count(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:13:40.464421Z",
     "start_time": "2018-03-06T15:13:40.458443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3207"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"perfect\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:14:40.070307Z",
     "start_time": "2018-03-06T15:14:40.061304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50117\n",
       "1     2731\n",
       "2      202\n",
       "3       16\n",
       "4        6\n",
       "Name: perfect, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"perfect\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:15:28.639806Z",
     "start_time": "2018-03-06T15:15:28.636306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now, write some code to compute the number of product reviews that contain the word perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:17:03.914940Z",
     "start_time": "2018-03-06T15:17:03.883938Z"
    }
   },
   "outputs": [],
   "source": [
    "products[\"contains_perfect\"]=products[\"perfect\"].apply(lambda x: 1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:17:16.668958Z",
     "start_time": "2018-03-06T15:17:16.662482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"contains_perfect\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 How many reviews in amazon_baby_subset.gl contain the word perfect?\n",
    "\n",
    "ans=2955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  convert data frame to a multi-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:30:14.590462Z",
     "start_time": "2018-03-06T15:30:14.578473Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(dataframe, features, label):\n",
    "    \n",
    "    dataframe[\"constant\"]=1\n",
    "    features = [\"constant\"] + features\n",
    "    \n",
    "    features_frame=dataframe[features]\n",
    "    feature_matrix=features_frame.as_matrix()\n",
    "    \n",
    "    label_sarray=dataframe[label]\n",
    "    label_array= label_sarray.as_matrix()\n",
    "    \n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T16:25:33.563684Z",
     "start_time": "2018-03-06T16:25:33.413163Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment= get_data(products,imp_words,\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:34:33.240232Z",
     "start_time": "2018-03-06T15:34:33.235232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:34:58.891564Z",
     "start_time": "2018-03-06T15:34:58.886543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 How many features are there in the feature_matrix?\n",
    "\n",
    "ans=194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating conditional probability with link function\n",
    "\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:49:21.855882Z",
     "start_time": "2018-03-06T15:49:21.846880Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    \n",
    "    score=np.dot(feature_matrix,coefficients)\n",
    "    prediction= 1. /(1 +np.exp(-score)) #link funcution\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T15:49:22.204223Z",
     "start_time": "2018-03-06T15:49:22.174218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "# check point\n",
    "\n",
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_predictions           =', correct_predictions)\n",
    "print('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute derivative of log likelihood with respect to a single coefficient\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T16:00:58.831894Z",
     "start_time": "2018-03-06T16:00:58.820893Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative=np.dot(errors, feature)\n",
    "    \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a function compute_log_likelihood that implements the equation\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T16:29:06.206866Z",
     "start_time": "2018-03-06T16:29:06.200364Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator= (sentiment==+1)\n",
    "    scores= np.dot(feature_matrix, coefficients)\n",
    "    lp=np.sum(indicator-1)*scores -np.log(1. + np.exp(-scores))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a function logistic_regression to fit a logistic regression model using gradient ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T16:49:12.030222Z",
     "start_time": "2018-03-06T16:49:11.997706Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    \n",
    "    coeff=np.array(initial_coefficients)\n",
    "    for itr in range(max_iter):\n",
    "        predictions=predict_probability(feature_matrix, coeff)\n",
    "        \n",
    "        indicator= (sentiment==+1)\n",
    "        errors=indicator - predictions\n",
    "        \n",
    "        for j in range(len(coeff)): # derivaTIVES for coeff[j]\n",
    "            derivative=np.dot(errors, feature_matrix[:,j])\n",
    "            \n",
    "            coeff[j]+= step_size*derivative #add step size\n",
    "            \n",
    "        # check if log likelyhood is increading\n",
    "        if itr <=15 or (itr<=100 and itr % 10 == 0) or (itr <=1000 and itr % 100==0) or (itr <=10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coeff)\n",
    "            print(\"iteration {}: log likelihood of observed labels = {}\".format( itr, lp))\n",
    "    return coeff\n",
    "\n",
    "#caqnt print out obs labels properly.... so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:28:09.688788Z",
     "start_time": "2018-03-06T17:27:36.304022Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: log likelihood of observed labels = [ -4.24976531   3.01182894  -1.24286656 ...,  41.41535663   0.84606707\n",
      "   6.78965943]\n",
      "iteration 1: log likelihood of observed labels = [ -7.81863918   6.70476282  -1.81120528 ...,  83.46928044   2.35452812\n",
      "  14.25632162]\n",
      "iteration 2: log likelihood of observed labels = [ -11.39968057   10.38572071   -2.39804466 ...,  125.46882548    3.83241215\n",
      "   21.70692469]\n",
      "iteration 3: log likelihood of observed labels = [ -14.99280179   14.0547685    -3.00326664 ...,  167.41419196    5.27989438\n",
      "   29.14155349]\n",
      "iteration 4: log likelihood of observed labels = [ -18.5979156    17.71197174   -3.62675386 ...,  209.3055791     6.69714911\n",
      "   36.5602924 ]\n",
      "iteration 5: log likelihood of observed labels = [ -22.21493528   21.3573956    -4.26838958 ...,  251.14318509    8.08434966\n",
      "   43.96322536]\n",
      "iteration 6: log likelihood of observed labels = [ -25.84377459   24.99110488   -4.92805773 ...,  292.92720717    9.44166845\n",
      "   51.35043582]\n",
      "iteration 7: log likelihood of observed labels = [ -29.48434777   28.61316407   -5.60564287 ...,  334.65784156   10.76927695\n",
      "   58.7220068 ]\n",
      "iteration 8: log likelihood of observed labels = [ -33.13656955   32.22363726   -6.30103022 ...,  376.3352835    12.06734569\n",
      "   66.07802086]\n",
      "iteration 9: log likelihood of observed labels = [ -36.80035515   35.82258822   -7.01410563 ...,  417.95972726   13.33604431\n",
      "   73.41856011]\n",
      "iteration 10: log likelihood of observed labels = [ -40.47562025   39.41008034   -7.74475559 ...,  459.53136613   14.57554151\n",
      "   80.74370621]\n",
      "iteration 11: log likelihood of observed labels = [ -44.16228101   42.9861767    -8.49286723 ...,  501.05039243   15.78600508\n",
      "   88.05354037]\n",
      "iteration 12: log likelihood of observed labels = [ -47.86025409   46.55093999   -9.2583283  ...,  542.51699751   16.9676019\n",
      "   95.34814338]\n",
      "iteration 13: log likelihood of observed labels = [ -51.56945658   50.10443259  -10.04102718 ...,  583.93137177   18.12049796\n",
      "  102.62759555]\n",
      "iteration 14: log likelihood of observed labels = [ -55.28980607   53.64671652  -10.84085289 ...,  625.29370464   19.24485832\n",
      "  109.89197678]\n",
      "iteration 15: log likelihood of observed labels = [ -59.02122061   57.17785347  -11.65769504 ...,  666.60418461   20.34084717\n",
      "  117.14136653]\n",
      "iteration 20: log likelihood of observed labels = [ -77.84143295   74.66846867  -15.99333262 ...,  872.38532203   25.40090311\n",
      "  153.1661936 ]\n",
      "iteration 30: log likelihood of observed labels = [ -116.2659157    108.84819018   -25.87911203 ...,  1280.16435082\n",
      "    33.4850558    224.13595258]\n",
      "iteration 40: log likelihood of observed labels = [ -155.67228226   142.00714939   -37.29860021 ...,  1683.04638845\n",
      "    38.98225908   293.72759866]\n",
      "iteration 50: log likelihood of observed labels = [ -195.98801936   174.200126     -50.15399192 ...,  2081.2006274\n",
      "    42.03855711   362.01174467]\n",
      "iteration 60: log likelihood of observed labels = [ -237.14466819   205.47893467   -64.35287961 ...,  2474.78794592\n",
      "    42.79218997   429.05520458]\n",
      "iteration 70: log likelihood of observed labels = [ -279.07761554   235.8925776    -79.80797548 ...,  2863.96131954\n",
      "    41.37398768   494.92118842]\n",
      "iteration 80: log likelihood of observed labels = [ -321.7258944    265.48739027   -96.43684601 ...,  3248.86621516\n",
      "    37.90774704   559.66948844]\n",
      "iteration 90: log likelihood of observed labels = [ -365.0319937    294.3071805   -114.1616585  ...,  3629.64096815\n",
      "    32.51059192   623.35665695]\n",
      "iteration 100: log likelihood of observed labels = [ -408.94167687   322.39336098  -132.90893948 ...,  4006.41714281\n",
      "    25.29331733   686.03617585]\n",
      "iteration 200: log likelihood of observed labels = [ -871.32262221   570.54022138  -363.14079875 ...,  7579.00362276\n",
      "  -126.5229936   1267.28265452]\n",
      "iteration 300: log likelihood of observed labels = [ -1353.02205437    777.25176277   -639.58210166 ...,  10857.58014415\n",
      "   -374.61794153   1789.11917694]\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, sentiment= get_data(products,imp_words,\"sentiment\")\n",
    "coeff=logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                         step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T16:42:50.250432Z",
     "start_time": "2018-03-06T16:42:50.246930Z"
    }
   },
   "source": [
    "## q4 it increases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:05:30.403538Z",
     "start_time": "2018-03-06T17:05:30.284518Z"
    }
   },
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(np.dot(feature_matrix, coeff), columns=[\"score\"])\n",
    "class_predictions=scores[\"score\"].apply(lambda x: 1 if x>0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:06:43.016542Z",
     "start_time": "2018-03-06T17:06:43.011041Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(class_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:07:01.728098Z",
     "start_time": "2018-03-06T17:07:01.720596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    27946\n",
       " 1    25126\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring accuracy\n",
    "\n",
    "accu= correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:12:21.711335Z",
     "start_time": "2018-03-06T17:12:21.695832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 39903\n",
      "# Reviews incorrectly classified = 13169\n",
      "# Reviews total                  = 53072\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "mistakes=(class_predictions != sentiment).sum()\n",
    "correct= len(sentiment) - mistakes\n",
    "accuracy=correct/float(len(sentiment))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print('# Reviews   correctly classified =', correct)\n",
    "print('# Reviews incorrectly classified =', mistakes)\n",
    "print('# Reviews total                  =', len(products))\n",
    "print(\"-----------------------------------------------------\")\n",
    "print('Accuracy = {:.2}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q6 What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)\n",
    "\n",
    "ans=0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which words contribute most to positive & negative sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:28:21.879416Z",
     "start_time": "2018-03-06T17:28:21.872442Z"
    }
   },
   "outputs": [],
   "source": [
    "coeffs = list(coeff[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(imp_words, coeffs)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Which of the following words is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:28:23.383889Z",
     "start_time": "2018-03-06T17:28:23.378387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.066546084170457681),\n",
       " ('love', 0.065890762922123258),\n",
       " ('easy', 0.06479458680257838),\n",
       " ('little', 0.045435626308421372),\n",
       " ('loves', 0.044976401394906038),\n",
       " ('well', 0.03013500109210707),\n",
       " ('perfect', 0.029739937104968459),\n",
       " ('old', 0.020077541034775385),\n",
       " ('nice', 0.018408707995268992),\n",
       " ('daughter', 0.017703199905701694)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8 ten most neg words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T17:28:25.765723Z",
     "start_time": "2018-03-06T17:28:25.759722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monitor', -0.024482100545891724),\n",
       " ('return', -0.026592778462247287),\n",
       " ('back', -0.027742697230661334),\n",
       " ('get', -0.028711552980192581),\n",
       " ('disappointed', -0.028978976142317068),\n",
       " ('even', -0.030051249236035808),\n",
       " ('work', -0.03306951529475273),\n",
       " ('money', -0.038982037286487116),\n",
       " ('product', -0.041511033392108904),\n",
       " ('would', -0.053860148445203128)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
